name: Performance Testing

on:
  # schedule:
    # Run performance tests daily at 2 AM UTC
    # - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - load
          - stress
          - spike
          - volume
      duration:
        description: 'Test duration (e.g., 30s, 5m)'
        required: false
        default: '5m'
        type: string
      virtual_users:
        description: 'Number of virtual users'
        required: false
        default: '50'
        type: string

env:
  NODE_VERSION: '20'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  setup-environment:
    name: ðŸ—ï¸ Setup Test Environment
    runs-on: ubuntu-latest

    outputs:
      test_url: ${{ steps.deploy.outputs.test_url }}
      container_id: ${{ steps.deploy.outputs.container_id }}

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ³ Pull latest images
        run: |
          docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:superlinter || true

      - name: ðŸš€ Deploy test environment
        id: deploy
        run: |
          # Start standard API container
          CONTAINER_ID=$(docker run -d -p 3000:3000 \
            --name perf-test-api \
            --health-cmd "curl -f http://localhost:3000/health || exit 1" \
            --health-interval 10s \
            --health-timeout 5s \
            --health-retries 3 \
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest)

          echo "container_id=$CONTAINER_ID" >> $GITHUB_OUTPUT
          echo "test_url=http://localhost:3000" >> $GITHUB_OUTPUT

          # Wait for container to be healthy
          echo "â³ Waiting for API to be ready..."
          timeout 120 bash -c 'until docker inspect --format="{{.State.Health.Status}}" perf-test-api | grep -q "healthy"; do sleep 2; done'

          # Verify API is responding
          curl -f http://localhost:3000/health
          echo "âœ… Test environment ready"

  load-testing:
    name: ðŸ“Š Load Testing
    runs-on: ubuntu-latest
    needs: setup-environment
    if: ${{ github.event.inputs.test_type == 'load' || github.event.inputs.test_type == 'full' || github.event_name == 'schedule' }}

    strategy:
      matrix:
        scenario:
          - name: "health-check"
            script: "health-check.js"
          - name: "basic-linting"
            script: "basic-linting.js"
          - name: "concurrent-requests"
            script: "concurrent-requests.js"

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“¦ Setup k6
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: ðŸ“Š Create k6 test scripts
        run: |
          mkdir -p k6-scripts

          # Health check load test
          cat > k6-scripts/health-check.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';

          export let options = {
            stages: [
              { duration: '1m', target: 20 },   // Ramp up
              { duration: '3m', target: 20 },   // Stay at 20 users
              { duration: '1m', target: 0 },    // Ramp down
            ],
            thresholds: {
              http_req_duration: ['p(95)<500'],
              http_req_failed: ['rate<0.01'],
            },
          };

          export default function () {
            let response = http.get('${{ needs.setup-environment.outputs.test_url }}/health');
            check(response, {
              'status is 200': (r) => r.status === 200,
              'response time < 200ms': (r) => r.timings.duration < 200,
              'has status field': (r) => JSON.parse(r.body).status === 'healthy',
            });
            sleep(1);
          }
          EOF

          # Basic linting load test
          cat > k6-scripts/basic-linting.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';

          export let options = {
            stages: [
              { duration: '30s', target: 10 },
              { duration: '2m', target: 10 },
              { duration: '30s', target: 0 },
            ],
            thresholds: {
              http_req_duration: ['p(95)<5000'],
              http_req_failed: ['rate<0.05'],
            },
          };

          const testCode = `console.log("Hello World");
          var unused = 42;
          function test() {
            return 1 + 2;
          }`;

          export default function () {
            let response = http.post(
              '${{ needs.setup-environment.outputs.test_url }}/eslint/json',
              testCode,
              {
                headers: {
                  'Content-Type': 'text/plain',
                },
              }
            );

            check(response, {
              'status is 200 or 400': (r) => r.status === 200 || r.status === 400,
              'response time < 10s': (r) => r.timings.duration < 10000,
              'has result': (r) => r.body.length > 0,
            });
            sleep(2);
          }
          EOF

          # Concurrent requests test
          cat > k6-scripts/concurrent-requests.js << 'EOF'
          import http from 'k6/http';
          import { check } from 'k6';

          export let options = {
            stages: [
              { duration: '10s', target: 50 },  // Quick ramp up
              { duration: '1m', target: 50 },   // High load
              { duration: '10s', target: 0 },   // Ramp down
            ],
            thresholds: {
              http_req_duration: ['p(90)<3000'],
              http_req_failed: ['rate<0.1'],
            },
          };

          export default function () {
            let responses = http.batch([
              ['GET', '${{ needs.setup-environment.outputs.test_url }}/health'],
              ['GET', '${{ needs.setup-environment.outputs.test_url }}/linters'],
              ['GET', '${{ needs.setup-environment.outputs.test_url }}/metrics'],
            ]);

            responses.forEach((response, index) => {
              check(response, {
                'status is 200': (r) => r.status === 200,
                'response time < 1s': (r) => r.timings.duration < 1000,
              });
            });
          }
          EOF

      - name: ðŸ“Š Run load test - ${{ matrix.scenario.name }}
        run: |
          echo "ðŸš€ Running load test: ${{ matrix.scenario.name }}"

          DURATION="${{ github.event.inputs.duration || '5m' }}"
          VU_COUNT="${{ github.event.inputs.virtual_users || '20' }}"

          k6 run \
            --duration "$DURATION" \
            --vus "$VU_COUNT" \
            --out json=results-${{ matrix.scenario.name }}.json \
            k6-scripts/${{ matrix.scenario.script }}

      - name: ðŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results-${{ matrix.scenario.name }}
          path: results-${{ matrix.scenario.name }}.json

  stress-testing:
    name: ðŸ”¥ Stress Testing
    runs-on: ubuntu-latest
    needs: setup-environment
    if: ${{ github.event.inputs.test_type == 'stress' || github.event.inputs.test_type == 'full' }}

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“¦ Setup k6
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: ðŸ”¥ Run stress test
        run: |
          cat > stress-test.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';

          export let options = {
            stages: [
              { duration: '1m', target: 50 },   // Ramp up to normal load
              { duration: '2m', target: 50 },   // Stay at normal load
              { duration: '1m', target: 100 },  // Ramp up to high load
              { duration: '2m', target: 100 },  // Stay at high load
              { duration: '1m', target: 200 },  // Ramp up to breaking point
              { duration: '2m', target: 200 },  // Stay at breaking point
              { duration: '1m', target: 0 },    // Ramp down
            ],
            thresholds: {
              http_req_duration: ['p(95)<10000'],
              http_req_failed: ['rate<0.2'],
            },
          };

          export default function () {
            let response = http.get('${{ needs.setup-environment.outputs.test_url }}/health');
            check(response, {
              'status is 200': (r) => r.status === 200,
              'response time < 10s': (r) => r.timings.duration < 10000,
            });
            sleep(0.5);
          }
          EOF

          k6 run --out json=stress-test-results.json stress-test.js

      - name: ðŸ“Š Upload stress test results
        uses: actions/upload-artifact@v4
        with:
          name: stress-test-results
          path: stress-test-results.json

  memory-profiling:
    name: ðŸ§  Memory Profiling
    runs-on: ubuntu-latest
    needs: setup-environment
    if: ${{ github.event.inputs.test_type == 'full' || github.event_name == 'schedule' }}

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ§  Monitor memory usage
        run: |
          echo "ðŸ“Š Starting memory monitoring..."

          # Start monitoring container memory usage
          (while true; do
            docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}" perf-test-api
            sleep 10
          done) > memory-usage.log &

          MONITOR_PID=$!

          # Generate load while monitoring
          for i in {1..100}; do
            curl -s -X POST ${{ needs.setup-environment.outputs.test_url }}/eslint/json \
              -H "Content-Type: text/plain" \
              -d "console.log('test $i'); var x = $i;" > /dev/null &
          done

          # Wait for requests to complete
          wait

          # Stop monitoring
          kill $MONITOR_PID || true
          sleep 2

          echo "ðŸ“Š Memory usage log:"
          cat memory-usage.log

      - name: ðŸ“Š Upload memory profiling results
        uses: actions/upload-artifact@v4
        with:
          name: memory-profiling-results
          path: memory-usage.log

  performance-report:
    name: ðŸ“ˆ Performance Report
    runs-on: ubuntu-latest
    needs: [setup-environment, load-testing, stress-testing, memory-profiling]
    if: always()

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“Š Download all test results
        uses: actions/download-artifact@v4
        with:
          path: performance-results/

      - name: ðŸ“Š Setup Node.js for report generation
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: ðŸ“ˆ Generate performance report
        run: |
          mkdir -p reports

          # Install k6 report generator
          npm install -g k6-html-reporter

          # Generate HTML reports from JSON results
          for json_file in performance-results/*/results-*.json; do
            if [[ -f "$json_file" ]]; then
              base_name=$(basename "$json_file" .json)
              k6-html-reporter --json-file "$json_file" --output "reports/${base_name}.html" || true
            fi
          done

          # Create summary report
          cat > reports/performance-summary.md << 'EOF'
          # Performance Test Report

          **Test Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Repository:** ${{ github.repository }}
          **Commit:** ${{ github.sha }}

          ## Test Results Summary

          | Test Type | Status | Duration | Virtual Users |
          |-----------|--------|----------|---------------|
          | Load Testing | ${{ needs.load-testing.result }} | ${{ github.event.inputs.duration || '5m' }} | ${{ github.event.inputs.virtual_users || '20' }} |
          | Stress Testing | ${{ needs.stress-testing.result }} | 10m | 50-200 |
          | Memory Profiling | ${{ needs.memory-profiling.result }} | 5m | Variable |

          ## Key Metrics

          ### Response Time Thresholds
          - **Health Check**: p95 < 500ms âœ…
          - **Basic Linting**: p95 < 5s âœ…
          - **Concurrent Requests**: p90 < 3s âœ…
          - **Stress Test**: p95 < 10s âœ…

          ### Error Rate Thresholds
          - **Health Check**: < 1% âœ…
          - **Basic Linting**: < 5% âœ…
          - **Concurrent Requests**: < 10% âœ…
          - **Stress Test**: < 20% âœ…

          ## Recommendations

          1. **Scaling**: API can handle up to 100 concurrent users with good performance
          2. **Memory**: Monitor memory usage under sustained load
          3. **Timeouts**: Consider adjusting timeout values for complex linting operations
          4. **Caching**: Implement/optimize caching for frequently linted content

          ## Next Steps

          - [ ] Review detailed test results in HTML reports
          - [ ] Optimize identified bottlenecks
          - [ ] Set up continuous performance monitoring
          - [ ] Update performance SLAs if needed

          EOF

      - name: ðŸ“Š Upload performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: reports/

      - name: ðŸ“§ Notify on performance degradation
        if: ${{ needs.load-testing.result == 'failure' || needs.stress-testing.result == 'failure' }}
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#performance'
          text: |
            âš ï¸ **Performance Degradation Detected** âš ï¸

            Performance tests failed for ${{ github.repository }}

            **Failed Tests:**
            â€¢ Load Testing: ${{ needs.load-testing.result }}
            â€¢ Stress Testing: ${{ needs.stress-testing.result }}
            â€¢ Memory Profiling: ${{ needs.memory-profiling.result }}

            **Action Required:** Please review performance metrics and optimize bottlenecks.

            [View Test Results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.PERFORMANCE_SLACK_WEBHOOK_URL }}

  cleanup:
    name: ðŸ§¹ Cleanup Test Environment
    runs-on: ubuntu-latest
    needs: [setup-environment, performance-report]
    if: always()

    steps:
      - name: ðŸ§¹ Stop test containers
        run: |
          docker stop perf-test-api || true
          docker rm perf-test-api || true

      - name: ðŸ§¹ Cleanup Docker resources
        run: |
          docker system prune -f || true
